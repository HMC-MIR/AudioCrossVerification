{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675526d8",
   "metadata": {},
   "source": [
    "# Implementing HSTW-MLv0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109961a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eer_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moffset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_offset \u001b[38;5;28;01mas\u001b[39;00m offset_hps\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sample\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eer_utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.spatial.distance import cdist\n",
    "import python_speech_features\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "from offset import find_offset as offset_hps\n",
    "from random import sample\n",
    "from eer_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14d709",
   "metadata": {},
   "source": [
    "## the HSTW portion of the system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e3a6b8",
   "metadata": {},
   "source": [
    "Code is adapted from HSTW GitHub repo notebook: 02a_HPTWAlign.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40402830",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4640c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from /home/arm/anaconda3/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1969,\n",
      "                 from /home/arm/anaconda3/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,\n",
      "                 from /home/arm/anaconda3/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:4,\n",
      "                 from /home/arm/.cache/ipython/cython/_cython_magic_ee7895a3f9ae4cc907619968bf5eb46a.c:710:\n",
      "/home/arm/anaconda3/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
      "   17 | #warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  ^~~~~~~\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "DTYPE_INT32 = np.int32\n",
    "ctypedef np.int32_t DTYPE_INT32_t\n",
    "\n",
    "DTYPE_FLOAT = np.float64\n",
    "ctypedef np.float64_t DTYPE_FLOAT_t\n",
    "\n",
    "cdef DTYPE_FLOAT_t MAX_FLOAT = float('inf')\n",
    "\n",
    "# @cython.boundscheck(False)\n",
    "def HSTW(double[:,:]C, float alpha, int beta=20, int gamma=1):\n",
    "    \"\"\"\n",
    "    C (np.array) : Cost matrix \n",
    "    alpha (float) : skip penalty for vertical transitions \n",
    "    beta (int) : plane transition penalty\n",
    "    gamma (int) : skip penalty for horizontal transitions\n",
    "    \n",
    "    returns\n",
    "        B (np.array) : Steps matrix\n",
    "        D (np.array) : Cumulative cost matrix\n",
    "    \"\"\"\n",
    "    # 0: visible, 1: hidden\n",
    "    # B: 1 Diag, 2 Right, 3 Up, 0 switch plane\n",
    "    # initialization\n",
    "    \n",
    "    cdef DTYPE_INT32_t numRows = C.shape[0]\n",
    "    cdef DTYPE_INT32_t numCols = C.shape[1]\n",
    "    \n",
    "    cdef np.ndarray[np.uint32_t, ndim=3] B = np.zeros((2, numRows,numCols), dtype=np.uint32)\n",
    "    cdef np.ndarray[DTYPE_FLOAT_t, ndim=3] D = np.ones((2, numRows, numCols), dtype=DTYPE_FLOAT) * MAX_FLOAT\n",
    "\n",
    "    cdef DTYPE_INT32_t i, j\n",
    "    cdef unsigned int best_step\n",
    "    cdef DTYPE_FLOAT_t cost, new_cost\n",
    "    \n",
    "    # bottom rows\n",
    "    D[0, 0] = C[0]\n",
    "    \n",
    "    # first cols\n",
    "    for i in range(1, C.shape[0]):\n",
    "        D[1, i, 0] = D[1, i-1, 0] + alpha\n",
    "        D[0, i, 0] = D[1, i, 0] + beta\n",
    "        B[0, i, 0] = 3\n",
    "        B[1, i, 0] = 0\n",
    "        \n",
    "    # rest of the matrix\n",
    "    for i in range(1, C.shape[0]):\n",
    "        for j in range(1, C.shape[1]):\n",
    "        \n",
    "            # hidden\n",
    "            # diag visible -> hidden, right in hidden, up in hidden\n",
    "            \n",
    "            cost = D[0, i-1, j-1] + gamma + alpha\n",
    "            step = 0\n",
    "            new_cost = D[1, i, j-1] + gamma\n",
    "            if new_cost < cost:\n",
    "                cost = new_cost\n",
    "                step = 2\n",
    "            new_cost = D[1, i-1, j] + alpha\n",
    "            if new_cost < cost:\n",
    "                cost = new_cost\n",
    "                step = 3\n",
    "            D[1, i, j] = cost\n",
    "            B[1, i, j] = step\n",
    "             \n",
    "            # visible\n",
    "            # hidden -> visible, diag\n",
    "            cost = D[1, i, j] + beta\n",
    "            step = 0\n",
    "            new_cost = D[0, i-1, j-1] + C[i, j]\n",
    "            if new_cost < cost:\n",
    "                cost = new_cost\n",
    "                step = 1\n",
    "            D[0, i, j] = cost\n",
    "            B[0, i, j] = step\n",
    "    return B, D\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def backtrace3D(unsigned int[:,:,:] B, double[:,:,:] D):\n",
    "    \"\"\"\n",
    "    B (np.array) : Steps matrix\n",
    "    D (np.array) : Cumulative cost matrix\n",
    "    \n",
    "    returns\n",
    "        path (np.array) : 3 columns representing [hidden? (bool), query frame, ref frame]\n",
    "    \"\"\"\n",
    "    cdef int p, r, c\n",
    "    cdef unsigned int step = 0\n",
    "    \n",
    "    p = 0\n",
    "    r = D.shape[1] - 1\n",
    "    c = np.argmin(D[0, D.shape[1] - 1])\n",
    "    cdef np.ndarray[np.int32_t, ndim=2] path_3D = np.zeros((D.shape[1]+D.shape[2], 3), dtype=np.int32)\n",
    "    \n",
    "    while r >= 0:\n",
    "        path_3D[step] = [p,r,c]\n",
    "        step += 1\n",
    "        if B[p, r, c] == 0 and p == 0:\n",
    "            p = 1\n",
    "            r -= 1\n",
    "            c -= 1\n",
    "        elif B[p, r, c] == 0 and p == 1:\n",
    "            p = 0\n",
    "        elif B[p, r, c] == 1:\n",
    "            r -= 1\n",
    "            c -= 1\n",
    "        elif B[p, r, c] == 2:\n",
    "            c -= 1\n",
    "        elif B[p, r, c] == 3:\n",
    "            r -= 1\n",
    "    return path_3D[:step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a68b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aligns a query file with its corresponding reference file and returns the 3-D path throught the HSTW tensor\n",
    "def alignHSTW(C, Ca = 2.4, Cb = 33, gamma = 3):\n",
    "    \"\"\"\n",
    "    C (np.array) : cost matrix of ref and query\n",
    "    Ca (float) : alpha parameter multiplier (see HSTW paper)\n",
    "    Cb (int) : beta parameter multiplier (see HSTW paper)\n",
    "    gamma (int) : skip penatly for horizontal transitions (see HSTW paper)\n",
    "    \n",
    "    returns\n",
    "        path (np.array) : 3 columns representing [hidden? (bool), query frame, ref frame]\n",
    "    \"\"\"\n",
    "    alpha = np.median(np.min(C, axis=1)) * Ca\n",
    "    B, D = HSTW(C, alpha, beta=(alpha+gamma)*Cb)\n",
    "    path_3D = backtrace3D(B, D)\n",
    "    return path_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157e595",
   "metadata": {},
   "source": [
    "## the ML portion of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8beb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_offset(C):\n",
    "    \"\"\"\n",
    "    C (np.array) : cost matrix of ref and query\n",
    "    \n",
    "    returns\n",
    "        min_offset (int) : frame at optimal diagonal path\n",
    "    \"\"\"\n",
    "    diag_sums = [C.diagonal(i).sum() for i in range(C.shape[1]-C.shape[0])]\n",
    "    min_offset = np.argmin(diag_sums)  \n",
    "    return min_offset\n",
    "\n",
    "def find_matching_frames(offset, path, threshold=0):\n",
    "    \"\"\"\n",
    "    offset (int) : frame at optimal diagonal path\n",
    "    path (np.array) : 3 columns representing [hidden? (bool), query frame, ref frame]\n",
    "    \n",
    "    returns\n",
    "        matching (np.array) : 3 columns representing [not matching? (bool), query frame, ref frame]\n",
    "    \"\"\"\n",
    "    matching = path.copy()\n",
    "    for idx, x in enumerate(matching):\n",
    "        plane, q, r = x\n",
    "        if plane == 0 and abs(r - q - offset) > threshold:\n",
    "            matching[idx][0] = 1\n",
    "    if np.sum(matching[:,0]) == 0:\n",
    "        return None\n",
    "    return matching\n",
    "\n",
    "def calculate_scores_H1(query, ref, matching, return_all=False):\n",
    "    \"\"\"\n",
    "    query (np.array) : mfcc features for query\n",
    "    ref (np.array) : mfcc features for reference\n",
    "    matching (np.array) : 3 columns representing [matching? (bool), query frame, ref frame]\n",
    "    \n",
    "    returns\n",
    "        (float) : H1 modified z-score \n",
    "    \"\"\"\n",
    "    matching_diffs = np.array([query[q] - ref[r] for m, q, r in matching if m == 0])\n",
    "    non_matching_diffs = np.array([query[q] - ref[r] for m, q, r in matching if m == 1])\n",
    "    mean, std = matching_diffs.mean(axis=0), matching_diffs.std(axis=0)\n",
    "    scores = (non_matching_diffs - mean) / std\n",
    "    if return_all:\n",
    "        return scores, mean, std\n",
    "    return np.abs(scores).mean()\n",
    "\n",
    "def calculate_scores_H2(query, ref, matching, return_all=False):\n",
    "    \"\"\"\n",
    "    query (np.array) : mfcc features for query\n",
    "    ref (np.array) : mfcc features for reference\n",
    "    matching (np.array) : 3 columns representing [matching? (bool), query frame, ref frame]\n",
    "    \n",
    "    returns\n",
    "        (float) : H2 modified z-score \n",
    "    \"\"\"\n",
    "    q_matching = query[matching[matching[:,0]==0][:,1]]\n",
    "    r_matching = ref[matching[matching[:,0]==0][:,2]]\n",
    "    mean, std = q_matching.mean(axis=0) - r_matching.mean(axis=0), q_matching.std(axis=0) + r_matching.std(axis=0)\n",
    "    non_matching_diffs = np.array([query[q] - ref[r] for m, q, r in matching if m == 1])\n",
    "    scores = (non_matching_diffs - mean) / std\n",
    "    if return_all:\n",
    "        return scores, mean, std\n",
    "    return np.abs(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8ba1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_to_mfcc(sec):\n",
    "    \"\"\"\n",
    "    sec (float): the optimal offset in seconds\n",
    "    \n",
    "    returns \n",
    "        (int): the corresponding mfcc frame\n",
    "    \"\"\"\n",
    "    winstep = 0.01\n",
    "    \n",
    "    return round(sec/winstep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f82bec",
   "metadata": {},
   "source": [
    "## lets start the big loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80389eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_DIR = './daps-mp3/test/mfccs/'\n",
    "\n",
    "queries = ['queries/' + file[:-4] for file in sorted(os.listdir(mfcc_DIR + 'queries/'))]\n",
    "tamp_025 = ['tampered0.25/' + file[:-4] for file in sorted(os.listdir(mfcc_DIR + 'tampered0.25/'))]\n",
    "tamp_05 = ['tampered0.5/' + file[:-4] for file in sorted(os.listdir(mfcc_DIR + 'tampered0.5/'))]\n",
    "tamp_1 = ['tampered1/' + file[:-4] for file in sorted(os.listdir(mfcc_DIR + 'tampered1/'))]\n",
    "tamp_2 = ['tampered2/' + file[:-4] for file in sorted(os.listdir(mfcc_DIR + 'tampered2/'))]\n",
    "tamp_4 = ['tampered4/' + file[:-4] for file in sorted(os.listdir(mfcc_DIR + 'tampered4/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88db5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dictionary of reference MFCCs\n",
    "ref_mfcc_dict = {file[:-10]: np.load(mfcc_DIR + 'refs/'+file) for file in sorted(os.listdir(mfcc_DIR + 'refs/'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ca4bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = queries + tamp_025 + tamp_05 + tamp_1 + tamp_2 + tamp_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cddd7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tamper_score(query):\n",
    "    \"\"\"\n",
    "    query (str) : name of query\n",
    "    \n",
    "    returns\n",
    "        tamper_type (str) : type of tampering, out of [NONE, INS, DEL, REP]\n",
    "        tamper_len (float) : tampering duration in seconds, out of [0.25, 0.5, 1, 2, 4]\n",
    "        bitrate (str) : bitrate of audio file, out of [64k, 128k, 256k]\n",
    "        ref_name (str) : name of reference used to generate query\n",
    "        query_no (int) : number of query\n",
    "        tamper_score (float) : difference of H1 and H2 z-scores\n",
    "    \"\"\"\n",
    "    query_type, query_name = query.split('/')\n",
    "\n",
    "    if query_type == \"queries\":\n",
    "        tamper_type = \"NONE\"\n",
    "        tamper_len = 0.\n",
    "    else:\n",
    "        tamper_type = query_name[:3].upper()\n",
    "        tamper_len = float(query_type[len('tampered'):])\n",
    "    \n",
    "    _, query_no, speaker, script, _ = query_name.split('_')\n",
    "    _, bitrate = query_name.split('-')\n",
    "    ref_name = f'{speaker}_{script}'\n",
    "    \n",
    "    # load query mfcc\n",
    "    query_mfcc = np.load(mfcc_DIR + query + '.npy')\n",
    "    \n",
    "    # load ref mfcc\n",
    "    ref_mfcc = ref_mfcc_dict[ref_name]\n",
    "    \n",
    "    # threshold delta delta and find offset\n",
    "    query_mhps = np.dot(query_mfcc[:,13:] > 0,np.power(2,np.arange(26))[::-1]).tolist()\n",
    "    ref_mhps = np.dot(ref_mfcc[:,13:] > 0,np.power(2,np.arange(26))[::-1]).tolist()\n",
    "    \n",
    "    offset = offset_hps(query_mhps, ref_mhps)\n",
    "    \n",
    "    start = max(0, offset-sec_to_mfcc(2.5))\n",
    "    end = min(offset+query_mfcc.shape[0]+sec_to_mfcc(2.5), ref_mfcc.shape[0])\n",
    "\n",
    "    \n",
    "    ref_mfcc = ref_mfcc[start:end]\n",
    "    \n",
    "    C = cdist(query_mfcc, ref_mfcc).astype('float64')\n",
    "    \n",
    "    # use HSTW to align query to reference\n",
    "    path = alignHSTW(C, Ca = 2.4, Cb = 33, gamma = 3)\n",
    "    \n",
    "    # find best diagonal path \n",
    "    best_offset = find_offset(C)\n",
    "    \n",
    "    # classify frames as matching or not\n",
    "    match = find_matching_frames(best_offset, path, threshold=0)\n",
    "    \n",
    "    if match is None:\n",
    "        tamper_score = 0\n",
    "        h1 = 0\n",
    "    elif np.all(match[:,0] == 1):\n",
    "        tamper_score = h1 = 100\n",
    "    else:\n",
    "        h1 = calculate_scores_H1(query_mfcc, ref_mfcc, match, return_all=False)\n",
    "        h2 = calculate_scores_H2(query_mfcc, ref_mfcc, match, return_all=False)\n",
    "        \n",
    "        tamper_score = h1 - h2\n",
    "    \n",
    "    return tamper_type, tamper_len, bitrate, ref_name, query_no, tamper_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "834de3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 24000/24000 [02:33<00:00, 156.02it/s]\n"
     ]
    }
   ],
   "source": [
    "p = Pool(39)\n",
    "with p:\n",
    "    results_queries = list(tqdm(p.imap_unordered(calculate_tamper_score, all_queries), total=len(all_queries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac777424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['type', 'len', 'bitrate', 'ref', 'query_no', 'score'], data=results_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0db5a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'mfccs'\n",
    "os.makedirs(f'./daps-mp3/results/{outdir}', exist_ok=True)\n",
    "df.to_csv(f'./daps-mp3/results/{outdir}/HSTW_cython_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5893fc5c",
   "metadata": {},
   "source": [
    "## Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e706d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./daps-mp3/results/mfccs/HSTW_cython_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0021aed1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bitrate \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m256k\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m128k\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m64k\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mget_eer_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbitrate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data0/Projects/AudioCrossVerification/utils.py:208\u001b[0m, in \u001b[0;36mget_eer_table\u001b[0;34m(results_df, bitrate)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     len_lab \u001b[38;5;241m=\u001b[39m lab\n\u001b[0;32m--> 208\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m(len_lab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruth\u001b[39m\u001b[38;5;124m'\u001b[39m], len_lab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    209\u001b[0m eer \u001b[38;5;241m=\u001b[39m calculate_eer(fpr, tpr)\n\u001b[1;32m    210\u001b[0m cols\u001b[38;5;241m.\u001b[39mappend(eer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "for bitrate in ['256k', '128k', '64k']:\n",
    "    get_eer_table(df, bitrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdbdef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
